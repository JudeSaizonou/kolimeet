# üì¶ Guide de Backfill - Correspondances de Colis/Trajets Existants

## üéØ Objectif

Ce guide d√©taille la proc√©dure pour g√©n√©rer les correspondances (matches) entre **tous les colis et trajets existants** dans la base de donn√©es, avant que le syst√®me de matching automatique ne soit activ√©.

---

## ‚ö†Ô∏è Pr√©-requis

### 1. V√©rifications Techniques

**Base de donn√©es:**
- ‚úÖ Migrations `20251125235959` et `20251126000001` appliqu√©es
- ‚úÖ Table `parcel_matches` existe
- ‚úÖ Vue `parcel_matches_detailed` existe
- ‚úÖ Triggers `auto_generate_parcel_matches` et `auto_generate_trip_matches` actifs

**V√©rifier via SQL:**
```sql
-- V√©rifier les tables
SELECT tablename FROM pg_tables 
WHERE schemaname = 'public' 
  AND tablename IN ('parcel_matches', 'parcels', 'trips');

-- V√©rifier les triggers
SELECT tgname, tgrelid::regclass 
FROM pg_trigger 
WHERE tgname LIKE '%match%';
```

### 2. Donn√©es Disponibles

**Compter les √©l√©ments √† traiter:**
```sql
-- Colis actifs
SELECT COUNT(*) FROM parcels WHERE status = 'active';

-- Trajets actifs  
SELECT COUNT(*) FROM trips WHERE status = 'active';

-- Estimation de matches possibles
SELECT 
  (SELECT COUNT(*) FROM parcels WHERE status = 'active') * 
  (SELECT COUNT(*) FROM trips WHERE status = 'active') 
  AS max_possible_matches;
```

### 3. Estimations de Temps

| Nombre de Colis | Nombre de Trajets | Temps Estim√© | Matches Max |
|-----------------|-------------------|--------------|-------------|
| 10              | 10                | < 1 seconde  | 100         |
| 100             | 100               | ~5 secondes  | 10,000      |
| 500             | 500               | ~30 secondes | 250,000     |
| 1,000           | 1,000             | ~2 minutes   | 1,000,000   |
| 5,000+          | 5,000+            | ~10+ minutes | 25,000,000+ |

‚ö†Ô∏è **Note:** Le temps r√©el d√©pend des ressources Supabase et de la complexit√© des routes.

---

## üöÄ Proc√©dure d'Ex√©cution

### √âtape 1: Dry Run (Simulation)

**Toujours commencer par un dry run pour estimer l'impact.**

```sql
-- Ex√©cuter dans le SQL Editor Supabase
SELECT backfill_parcel_matches(
  p_dry_run := TRUE,     -- Mode simulation
  p_batch_size := 100    -- 100 items par batch
);
```

**R√©sultat attendu:**
```json
{
  "success": true,
  "dry_run": true,
  "duration_seconds": 5,
  "total_parcels": 150,
  "total_trips": 200,
  "matches_created": 4500,  // Estimation
  "matches_skipped": 25500,
  "errors": 0,
  "batch_size": 100
}
```

**Analyser le r√©sultat:**
- ‚úÖ `success: true` ‚Üí Tout est OK
- ‚ö†Ô∏è `errors > 0` ‚Üí V√©rifier les logs pour identifier les probl√®mes
- üìä `matches_created` ‚Üí Nombre estim√© de matches qui seront cr√©√©s

---

### √âtape 2: Backup (Recommand√©)

**Cr√©er une sauvegarde avant le backfill:**

```sql
-- Cr√©er une table de backup
CREATE TABLE parcel_matches_backup_20241126 AS 
SELECT * FROM parcel_matches;

-- V√©rifier le backup
SELECT COUNT(*) FROM parcel_matches_backup_20241126;
```

---

### √âtape 3: Ex√©cution Production

**Une fois le dry run valid√©, ex√©cuter en mode production:**

```sql
-- ‚ö†Ô∏è Ceci va cr√©er r√©ellement les matches dans la base de donn√©es
SELECT backfill_parcel_matches(
  p_dry_run := FALSE,    -- Mode production
  p_batch_size := 100    -- Ajuster si n√©cessaire
);
```

**Suivi en temps r√©el:**
Le script affiche la progression dans les logs:
```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  BACKFILL PARCEL MATCHES - D√âMARRAGE                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚öôÔ∏è  Mode: PRODUCTION
üì¶ Batch size: 100
üïê Heure de d√©marrage: 2024-11-26 10:00:00

üìä Statistiques:
   ‚Ä¢ Colis actifs: 150
   ‚Ä¢ Trajets actifs: 200
   ‚Ä¢ Nombre de batchs: 2
   ‚Ä¢ Matches max possibles: 30000

üöÄ D√©but du traitement par batch...

üì¶ Batch 1/2 - Processing parcel abc123... (from: Paris, to: Cotonou)
   ‚≠ê Excellent match trouv√©: score=95 (parcel abc123 ‚Üí trip def456)
üì¶ Batch 2/2 - Processing parcel xyz789... (from: Lyon, to: Dakar)

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  BACKFILL TERMIN√â                                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìä R√©sum√©:
   ‚Ä¢ Matches cr√©√©s: 4500
   ‚Ä¢ Matches ignor√©s: 25500
   ‚Ä¢ Erreurs: 0
   ‚Ä¢ Dur√©e: 8 secondes
```

---

### √âtape 4: Validation

**Ex√©cuter la validation automatique:**

```sql
SELECT validate_backfill_results();
```

**R√©sultat attendu:**
```json
{
  "total_matches": 4500,
  "duplicates": 0,           // DOIT √™tre 0
  "invalid_scores": 0,       // DOIT √™tre 0
  "invalid_status": 0,       // DOIT √™tre 0
  "orphan_parcels": 0,       // DOIT √™tre 0
  "orphan_trips": 0,         // DOIT √™tre 0
  "is_valid": true           // DOIT √™tre true
}
```

**Validation manuelle suppl√©mentaire:**

```sql
-- Voir le fichier scripts/validate-backfill.sql pour plus de requ√™tes

-- 1. Distribution des scores
SELECT 
  CASE 
    WHEN match_score >= 90 THEN '‚≠ê Excellent (90-100%)'
    WHEN match_score >= 70 THEN 'üîµ Bon (70-89%)'
    WHEN match_score >= 50 THEN 'üü° Acceptable (50-69%)'
  END as score_range,
  COUNT(*) as count,
  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM parcel_matches), 2) as percentage
FROM parcel_matches
GROUP BY score_range
ORDER BY MIN(match_score) DESC;

-- 2. Top 10 meilleurs matches
SELECT 
  pm.match_score,
  p.from_city || ' ‚Üí ' || p.to_city as parcel_route,
  t.from_city || ' ‚Üí ' || t.to_city as trip_route,
  p.weight_kg || 'kg' as weight,
  t.date_departure
FROM parcel_matches pm
JOIN parcels p ON p.id = pm.parcel_id
JOIN trips t ON t.id = pm.trip_id
ORDER BY pm.match_score DESC
LIMIT 10;
```

---

## ‚úÖ Checklist de Validation

Cocher chaque √©l√©ment avant de consid√©rer le backfill comme r√©ussi:

- [ ] **Dry run ex√©cut√©** avec succ√®s (errors = 0)
- [ ] **Backup cr√©√©** (si applicable)
- [ ] **Production ex√©cut√©e** sans erreurs
- [ ] **Validation automatique** retourne `is_valid: true`
- [ ] **Aucun doublon** d√©tect√©
- [ ] **Tous les scores** sont entre 50 et 100
- [ ] **Aucun orphelin** (r√©f√©rences vers colis/trajets inexistants)
- [ ] **Distribution des scores** coh√©rente (majoritairement 50-89%)
- [ ] **Top matches** v√©rifi√©s manuellement (routes logiques)
- [ ] **Temps d'ex√©cution** raisonnable (< estimation)

---

## üî• Probl√®mes Courants & Solutions

### Probl√®me 1: Timeout pendant l'ex√©cution

**Sympt√¥mes:**
```
ERROR: timeout exceeded
```

**Solutions:**
1. R√©duire le `batch_size`:
   ```sql
   SELECT backfill_parcel_matches(FALSE, 50);  -- Au lieu de 100
   ```

2. Ex√©cuter par tranches (colis r√©cents d'abord):
   ```sql
   -- Cr√©er une fonction pour traiter uniquement les N derniers colis
   CREATE FUNCTION backfill_recent_parcels(p_limit INTEGER)
   RETURNS JSON AS $$
   BEGIN
     -- Logique similaire mais avec LIMIT sur la boucle
   END;
   $$ LANGUAGE plpgsql;
   ```

---

### Probl√®me 2: Erreurs durant le traitement

**Sympt√¥mes:**
```
üìä R√©sum√©:
   ‚Ä¢ Erreurs: 25
```

**Solutions:**
1. Consulter les logs d√©taill√©s:
   ```sql
   -- Les erreurs sont affich√©es dans les NOTICE
   -- Chercher les lignes commen√ßant par "‚ùå Erreur"
   ```

2. Identifier les colis/trajets probl√©matiques:
   ```sql
   -- V√©rifier les colis avec donn√©es incompl√®tes
   SELECT id, from_country, to_country, from_city, to_city
   FROM parcels
   WHERE status = 'active'
     AND (from_country IS NULL OR to_country IS NULL);
   ```

3. Corriger les donn√©es et relancer

---

### Probl√®me 3: Doublons d√©tect√©s

**Sympt√¥mes:**
```json
{
  "duplicates": 150
}
```

**Solutions:**
```sql
-- Supprimer les doublons (garder le plus ancien)
DELETE FROM parcel_matches
WHERE id NOT IN (
  SELECT DISTINCT ON (parcel_id, trip_id) id
  FROM parcel_matches
  ORDER BY parcel_id, trip_id, created_at
);

-- Re-valider
SELECT validate_backfill_results();
```

---

### Probl√®me 4: Scores invalides

**Sympt√¥mes:**
```json
{
  "invalid_scores": 45
}
```

**Solutions:**
```sql
-- Identifier les scores invalides
SELECT id, match_score, parcel_id, trip_id
FROM parcel_matches
WHERE match_score < 50 OR match_score > 100;

-- Recalculer les scores
UPDATE parcel_matches pm
SET match_score = calculate_match_score(pm.parcel_id, pm.trip_id)
WHERE match_score < 50 OR match_score > 100;

-- Supprimer ceux qui restent < 50
DELETE FROM parcel_matches WHERE match_score < 50;
```

---

## üîÑ Plan de Rollback

### Rollback Complet (Annuler tout)

**Si le backfill a √©chou√© ou produit des r√©sultats incorrects:**

```sql
-- Option 1: Utiliser la fonction de rollback
SELECT remove_all_backfilled_matches();

-- Option 2: Restaurer depuis le backup
TRUNCATE parcel_matches;
INSERT INTO parcel_matches SELECT * FROM parcel_matches_backup_20241126;

-- V√©rifier
SELECT COUNT(*) FROM parcel_matches;
```

### Rollback Partiel (Annuler les r√©cents uniquement)

**Si vous voulez garder les anciens matches:**

```sql
-- Supprimer les matches cr√©√©s dans la derni√®re heure
DELETE FROM parcel_matches 
WHERE created_at > NOW() - INTERVAL '1 hour';

-- Ou supprimer ceux cr√©√©s apr√®s une date sp√©cifique
DELETE FROM parcel_matches 
WHERE created_at > '2024-11-26 10:00:00';
```

**Voir le fichier `scripts/rollback-backfill.sql` pour plus d'options.**

---

## üìä Monitoring Post-Backfill

### M√©triques √† Surveiller

**Dashboard Supabase > Database > Performance**
- Temps de r√©ponse des requ√™tes sur `parcel_matches`
- Utilisation du stockage (table + index)
- Nombre de scans s√©quentiels (doit √™tre bas)

**Requ√™tes de monitoring:**

```sql
-- Croissance de la table
SELECT 
  pg_size_pretty(pg_total_relation_size('parcel_matches')) as total_size,
  pg_size_pretty(pg_relation_size('parcel_matches')) as table_size,
  pg_size_pretty(pg_indexes_size('parcel_matches')) as indexes_size;

-- Performance des index
SELECT 
  schemaname,
  tablename,
  indexname,
  idx_scan,
  idx_tup_read,
  idx_tup_fetch
FROM pg_stat_user_indexes
WHERE tablename = 'parcel_matches'
ORDER BY idx_scan DESC;

-- Requ√™tes lentes
SELECT 
  query,
  mean_exec_time::INTEGER as avg_ms,
  calls
FROM pg_stat_statements
WHERE query LIKE '%parcel_matches%'
ORDER BY mean_exec_time DESC
LIMIT 5;
```

---

## üéì FAQ

### Q1: Dois-je ex√©cuter le backfill pour chaque nouvel utilisateur?

**Non.** Le backfill est une op√©ration **unique** pour matcher les donn√©es existantes. Les nouveaux colis/trajets seront automatiquement match√©s par les triggers.

---

### Q2: Combien de temps les matches restent-ils valides?

Les matches expirent automatiquement si:
- La date de d√©part du trajet est pass√©e
- La deadline du colis est d√©pass√©e

Utiliser la fonction `cleanup_expired_matches()` r√©guli√®rement (via cron job).

---

### Q3: Que se passe-t-il si j'ex√©cute le backfill deux fois?

**Rien de grave.** La migration est **idempotente** gr√¢ce √† la contrainte `UNIQUE(parcel_id, trip_id)`. Les doublons sont automatiquement ignor√©s.

---

### Q4: Puis-je annuler le backfill apr√®s ex√©cution?

**Oui**, via la fonction de rollback:
```sql
SELECT remove_all_backfilled_matches();
```

Ou restaurer depuis le backup si cr√©√©.

---

### Q5: Le backfill envoie-t-il des notifications aux utilisateurs?

**Non.** Pour √©viter de spammer les utilisateurs avec des centaines de notifications, le backfill **ne d√©clenche PAS** le trigger `notify_on_new_match`. Seuls les **nouveaux** matches (apr√®s le backfill) g√©n√®rent des notifications.

---

## üìû Support

**En cas de probl√®me:**
- üìñ Consulter ce guide
- üîç V√©rifier `scripts/validate-backfill.sql`
- üîÑ Utiliser `scripts/rollback-backfill.sql` si n√©cessaire
- üí¨ Contacter l'√©quipe technique

**Logs Supabase:**
Dashboard > Database > Logs > Postgres Logs

---

## ‚úÖ R√©sum√© de la Proc√©dure

1. ‚úÖ V√©rifier les pr√©-requis (tables, triggers, donn√©es)
2. ‚úÖ Ex√©cuter un **dry run** pour estimation
3. ‚úÖ Cr√©er un **backup** (recommand√©)
4. ‚úÖ Ex√©cuter en **production**
5. ‚úÖ **Valider** les r√©sultats (automatique + manuel)
6. ‚úÖ V√©rifier la **checklist de validation**
7. ‚úÖ Configurer le **monitoring**
8. ‚úÖ (Optionnel) Configurer un **cron job** de nettoyage

**Temps total estim√©:** 10-30 minutes (selon la taille des donn√©es)

---

**Bon backfill ! üöÄ**
